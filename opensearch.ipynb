{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook demonstrates how to:\n",
    "\n",
    "1. Connect to a local Dockerized OpenSearch instance.\n",
    "2. Create and configure an OpenSearch index for vector storage.\n",
    "3. Use LangChain to split large Python code into manageable chunks.\n",
    "4. Generate embeddings using Cohere's embed-english-v3 model from Amazon Bedrock.\n",
    "5. Store the embeddings and text chunks in OpenSearch.\n",
    "6. Execute vector searches based on different queries and analyze search accuracy.\n",
    "7. Optimize retrieval by addressing common mistakes.\n",
    "\n",
    "Ensure you have:\n",
    "- A local Dockerized OpenSearch instance running on the default port (9200).\n",
    "- Valid AWS credentials configured for accessing Amazon Bedrock (for embeddings).\n",
    "- The necessary Python dependencies installed (opensearch-py, langchain, boto3, etc.).\n",
    "\n",
    "Let's get started!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 2: Imports and Preliminary Setup\n",
    "\n",
    "import os\n",
    "import json\n",
    "import time\n",
    "import boto3\n",
    "import uuid\n",
    "import requests\n",
    "from typing import List\n",
    "\n",
    "# OpenSearch client from opensearch-py\n",
    "from opensearchpy import OpenSearch, RequestsHttpConnection, helpers\n",
    "\n",
    "# LangChain text splitters\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.text_splitter import Language\n",
    "\n",
    "\n",
    "# import warnings\n",
    "# from urllib3.exceptions import InsecureRequestWarning\n",
    "\n",
    "# warnings.simplefilter(\"ignore\", InsecureRequestWarning)\n",
    "\n",
    "\n",
    "# Adjust these settings if needed\n",
    "OPENSEARCH_HOST = \"localhost\"\n",
    "OPENSEARCH_PORT = 9200\n",
    "OPENSEARCH_USER = \"admin\"  # If you have authentication\n",
    "OPENSEARCH_PASS = \"*asca9schasihca0CE\"  # Replace if you've set a different password\n",
    "\n",
    "# For Amazon Bedrock usage:\n",
    "REGION_NAME = \"ap-southeast-2\"  # or your region\n",
    "BEDROCK_MODEL_ID = \"cohere.embed-english-v3\"\n",
    "\n",
    "# Index name in OpenSearch\n",
    "INDEX_NAME = \"code-embeddings-index\"\n",
    "\n",
    "# Additional configurations\n",
    "CHUNK_SIZE = 200\n",
    "CHUNK_OVERLAP = 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\marcu\\.conda\\envs\\MachineLearning\\Lib\\site-packages\\opensearchpy\\connection\\http_requests.py:157: UserWarning: Connecting to https://localhost:9200 using SSL with verify_certs=False is insecure.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connected to OpenSearch. Cluster health: yellow\n",
      "Created index 'code-embeddings-index'\n"
     ]
    }
   ],
   "source": [
    "# Cell 3: Connect to OpenSearch and Create Index If Needed\n",
    "\n",
    "# Create the OpenSearch client\n",
    "# If you have no auth, you might omit http_auth. Adjust verify_certs or use SSL as needed.\n",
    "auth = (OPENSEARCH_USER, OPENSEARCH_PASS)\n",
    "client = OpenSearch(\n",
    "    hosts=[{\"host\": OPENSEARCH_HOST, \"port\": OPENSEARCH_PORT}],\n",
    "    http_auth=auth,\n",
    "    use_ssl=True,\n",
    "    verify_certs=False,\n",
    "    connection_class=RequestsHttpConnection,\n",
    ")\n",
    "\n",
    "# Check connection\n",
    "try:\n",
    "    health = client.cluster.health()\n",
    "    print(\"Connected to OpenSearch. Cluster health:\", health[\"status\"])\n",
    "except Exception as e:\n",
    "    print(\"Failed to connect to OpenSearch:\", e)\n",
    "    raise e\n",
    "\n",
    "# Create index mapping for vector search\n",
    "index_body = {\n",
    "    \"settings\": {\n",
    "        \"index\": {\n",
    "            \"knn\": True,\n",
    "            \"number_of_shards\": 1,\n",
    "            \"number_of_replicas\": 0\n",
    "        },\n",
    "        \"analysis\": {\n",
    "            \"analyzer\": {\n",
    "                \"keyword_analyzer\": {\n",
    "                    \"type\": \"custom\",\n",
    "                    \"tokenizer\": \"keyword\",\n",
    "                    \"filter\": [\"lowercase\"]\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "    },\n",
    "    \"mappings\": {\n",
    "        \"properties\": {\n",
    "            \"text\": {\"type\": \"text\", \"analyzer\": \"keyword_analyzer\"},\n",
    "            \"embedding\": {\n",
    "                \"type\": \"knn_vector\",\n",
    "                \"dimension\": 1024,  # This is the dimension for Cohere embed-english-v3 (example dimension)\n",
    "                \"method\": {\n",
    "                    \"name\": \"hnsw\",\n",
    "                    \"space_type\": \"cosinesimil\",\n",
    "                    \"engine\": \"nmslib\",\n",
    "                    \"parameters\": {\n",
    "                        \"m\": 16,\n",
    "                        \"ef_construction\": 100\n",
    "                    }\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "client.indices.delete(index=INDEX_NAME, ignore=[400, 404])\n",
    "# Create or update index\n",
    "if not client.indices.exists(index=INDEX_NAME):\n",
    "    client.indices.create(index=INDEX_NAME, body=index_body)\n",
    "    print(f\"Created index '{INDEX_NAME}'\")\n",
    "else:\n",
    "    print(f\"Index '{INDEX_NAME}' already exists.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of chunks created: 498\n"
     ]
    }
   ],
   "source": [
    "# Cell 4: Read and Split Sample Python Code\n",
    "\n",
    "# Assume 'src/sample.py' is a file with ~2500 lines of example Python code\n",
    "# For demonstration, ensure you have this file in your local environment\n",
    "sample_file_path = \"src/sample_garbled.py\"\n",
    "\n",
    "if not os.path.exists(sample_file_path):\n",
    "    raise FileNotFoundError(f\"Could not find the file: {sample_file_path}\")\n",
    "\n",
    "with open(sample_file_path, \"r\", encoding=\"utf-8\") as f:\n",
    "    code_data = f.read()\n",
    "\n",
    "extra_splitters = ['\\nclass','\\ndef']\n",
    "# Use LangChain's RecursiveCharacterTextSplitter with Python-specific splitting\n",
    "splitter = RecursiveCharacterTextSplitter(\n",
    "    RecursiveCharacterTextSplitter.get_separators_for_language(Language.PYTHON).extend(extra_splitters),\n",
    "    chunk_size=CHUNK_SIZE,\n",
    "    chunk_overlap=CHUNK_OVERLAP,\n",
    ")\n",
    "chunks = splitter.split_text(code_data)\n",
    "print(f\"Number of chunks created: {len(chunks)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 5: Set Up Amazon Bedrock for Cohere Embeddings\n",
    "\n",
    "# Create a Bedrock runtime client with credentials as a parameter\n",
    "bedrock = boto3.client(\"bedrock-runtime\", region_name=REGION_NAME,\n",
    "    aws_access_key_id=\"YOUR_ACCESS_KEY\",\n",
    "    aws_secret_access_key=\"YoUR_SECRET_ACCESS\",\n",
    "    aws_session_token=\"YOUR_SESSION_TOKEN\"\n",
    ")\n",
    "def cohere_embed_texts(texts, model_id):\n",
    "    # texts is a list of strings\n",
    "    if not texts:\n",
    "        return []\n",
    "\n",
    "    # Prepare the request body for Cohere's embed-english-v3\n",
    "    body_dict = {\n",
    "        \"texts\": texts,                  # A list of strings\n",
    "        \"input_type\": \"search_document\"  # or \"query\" if you're embedding queries\n",
    "    }\n",
    "\n",
    "    response = bedrock.invoke_model(\n",
    "        modelId=model_id,\n",
    "        contentType=\"application/json\",\n",
    "        accept=\"application/json\",\n",
    "        body=json.dumps(body_dict)\n",
    "    )\n",
    "\n",
    "    resp_body = json.loads(response[\"body\"].read())\n",
    "    # For embed-english-v3, the model returns { \"embeddings\": [ [vector], [vector], ... ] }\n",
    "    # so you get an embedding for each text in the input.\n",
    "    embeddings = resp_body[\"embeddings\"]  # list of lists\n",
    "    return embeddings\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Indexing completed. Bulk response: (498, [])\n"
     ]
    }
   ],
   "source": [
    "# Cell 6: Generate Embeddings for Each Chunk and Index into OpenSearch\n",
    "\n",
    "docs_to_index = []\n",
    "batch_size = 16\n",
    "all_chunks = chunks[:]  # Copy for manipulation\n",
    "\n",
    "while all_chunks:\n",
    "    batch = all_chunks[:batch_size]\n",
    "    all_chunks = all_chunks[batch_size:]\n",
    "\n",
    "    # Generate embeddings via Amazon Bedrock\n",
    "    batch_embeddings = cohere_embed_texts(batch, BEDROCK_MODEL_ID)\n",
    "\n",
    "    for text_chunk, embedding in zip(batch, batch_embeddings):\n",
    "        doc_id = str(uuid.uuid4())\n",
    "        doc_body = {\n",
    "            \"text\": text_chunk,\n",
    "            \"embedding\": embedding\n",
    "        }\n",
    "        docs_to_index.append({\n",
    "            \"_index\": INDEX_NAME,\n",
    "            \"_id\": doc_id,\n",
    "            \"_source\": doc_body\n",
    "        })\n",
    "\n",
    "# Use bulk helper to index all\n",
    "resp = helpers.bulk(client, docs_to_index)\n",
    "print(\"Indexing completed. Bulk response:\", resp)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index refreshed and ready for search.\n"
     ]
    }
   ],
   "source": [
    "# Cell 7: Refresh Index and Prepare for Searches\n",
    "\n",
    "# Refresh so that newly indexed documents are available\n",
    "client.indices.refresh(index=INDEX_NAME)\n",
    "print(\"Index refreshed and ready for search.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 25 queries:\n",
      "- Parsing imports with resolvers\n",
      "- Reverse words in a string\n",
      "- Simple linear regression\n",
      "- SQLite insertion and retrieval\n",
      "- Random BST creation\n",
      "- Web scraping with HTML parsing\n",
      "- Random string generation\n",
      "- Basic XOR encryption\n",
      "- K-Means clustering\n",
      "- SHA-256 string hashing\n",
      "- JSON string parsing\n",
      "- Simple socket server\n",
      "- BFS graph traversal\n",
      "- Reading CSV files\n",
      "- String compression with run-length encoding\n",
      "- BST value search\n",
      "- Partial censor for words\n",
      "- In-place list shuffling\n",
      "- Naive Bayes classifier\n",
      "- Flatten nested lists\n",
      "- GCD and LCM of lists\n",
      "- String rotation\n",
      "- Creating temp files\n",
      "- Combine dictionaries\n",
      "- Simple MultiLayer Perceptron\n"
     ]
    }
   ],
   "source": [
    "# Cell 8: Define Test Queries for Different Programming Tasks\n",
    "\n",
    "# Cell: Import Queries\n",
    "\n",
    "from src.test_queries import test_queries\n",
    "\n",
    "# Confirm they're loaded\n",
    "print(f\"Loaded {len(test_queries)} queries:\")\n",
    "for q in test_queries:\n",
    "    print(\"-\", q[\"description\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 9: Implement a Vector kNN Search in OpenSearch\n",
    "\n",
    "def vector_search_opensearch(query_text: str, k: int = 5):\n",
    "    \"\"\"\n",
    "    Perform a vector search in OpenSearch using the query text embedded by Cohere.\n",
    "    Return top k results.\n",
    "    \"\"\"\n",
    "    # Embed query\n",
    "    query_embedding = cohere_embed_texts([query_text], BEDROCK_MODEL_ID)[0]\n",
    "\n",
    "    # Construct kNN query\n",
    "    search_body = {\n",
    "        \"size\": k,\n",
    "        \"query\": {\n",
    "            \"knn\": {\n",
    "                \"embedding\": {\n",
    "                    \"vector\": query_embedding,\n",
    "                    \"k\": k\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "\n",
    "    try:\n",
    "        response = client.search(index=INDEX_NAME, body=search_body)\n",
    "        hits = response[\"hits\"][\"hits\"]\n",
    "        return hits\n",
    "    except Exception as e:\n",
    "        print(f\"Search error: {e}\")\n",
    "        return []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "## Test 1: Parsing imports with resolvers\n",
      "\n",
      "**Query**: Which function can find all the import statements in Python code?\n",
      "\n",
      "**Expected Keywords**: import, resolver, find_imports, ImportResolver\n",
      "\n",
      "### Rank 1 | Score: 0.71679586\n",
      "\n",
      "```python\n",
      "import sys\n",
      "import os\n",
      "import math\n",
      "import random\n",
      "import sqlite3\n",
      "import urllib.request\n",
      "import urllib.parse\n",
      "import http.client\n",
      "import socket\n",
      "import itertools\n",
      "import json\n",
      "import re\n",
      "import csv\n",
      "```\n",
      "\n",
      "### Rank 2 | Score: 0.6987251\n",
      "\n",
      "```python\n",
      "if vyrk_hbim.startswith(\"import \"):\n",
      "                ouqi_rhjz = vyrk_hbim.split()[1]\n",
      "                cwkj_rqyu.append(ouqi_rhjz)\n",
      "            elif vyrk_hbim.startswith(\"from \"):\n",
      "```\n",
      "\n",
      "### Rank 3 | Score: 0.6975831\n",
      "\n",
      "```python\n",
      "if qsob_cihx.strip().startswith('import '):\n",
      "                iblp_mhte = qsob_cihx.strip().split('import ')[1].split()[0]\n",
      "                eqkj_ynps.append(iblp_mhte)\n",
      "```\n",
      "\n",
      "No result contained all expected keywords. ❌\n",
      "\n",
      "## Test 2: Reverse words in a string\n",
      "\n",
      "**Query**: How do I reverse the words in a sentence for string manipulation?\n",
      "\n",
      "**Expected Keywords**: reverse_words_in_string, split, string manipulation\n",
      "\n",
      "### Rank 1 | Score: 0.67386806\n",
      "\n",
      "```python\n",
      "break\n",
      "            yield xyha_pfgz\n",
      "```\n",
      "\n",
      "### Rank 2 | Score: 0.6728755\n",
      "\n",
      "```python\n",
      "def mmol_plrg(qxgw_nlds, ojvk_aafh):\n",
      "    pxyu_helf = rqac_lpnv(qxgw_nlds)\n",
      "    pxyu_helf.reverse()\n",
      "    fkkh_ytgh(ojvk_aafh, pxyu_helf)\n",
      "```\n",
      "\n",
      "### Rank 3 | Score: 0.66173387\n",
      "\n",
      "```python\n",
      "jgiy_zixm = itui_xhbr[jgiy_zixm]\n",
      "                dtum_qkrv.reverse()\n",
      "                return dtum_qkrv\n",
      "            for nbkl_zuhp in mgys_tkvw(jgiy_zixm):\n",
      "```\n",
      "\n",
      "No result contained all expected keywords. ❌\n",
      "\n",
      "## Test 3: Simple linear regression\n",
      "\n",
      "**Query**: I need a basic function for linear regression that can train and predict values.\n",
      "\n",
      "**Expected Keywords**: BasicRegressionModel, fit, predict\n",
      "\n",
      "### Rank 1 | Score: 0.67793703\n",
      "\n",
      "```python\n",
      "return set(qbzo_lpae)\n",
      "```\n",
      "\n",
      "### Rank 2 | Score: 0.6757501\n",
      "\n",
      "```python\n",
      "return list(ybgd_zvsa)\n",
      "```\n",
      "\n",
      "### Rank 3 | Score: 0.67095006\n",
      "\n",
      "```python\n",
      "fdtl_jovu += 1\n",
      "    return nxyi_tlwq\n",
      "```\n",
      "\n",
      "No result contained all expected keywords. ❌\n",
      "\n",
      "## Test 4: SQLite insertion and retrieval\n",
      "\n",
      "**Query**: Which snippet shows a method to insert and select rows from an SQLite database?\n",
      "\n",
      "**Expected Keywords**: INSERT INTO, SELECT, sqlite3, simple_database_insert, simple_database_fetch_all\n",
      "\n",
      "### Rank 1 | Score: 0.7058879\n",
      "\n",
      "```python\n",
      "kmvz_udiz.execute('INSERT INTO items (name, value) VALUES (?, ?)', (uvlg_gcki, yqey_pkop))\n",
      "    wuvt_fpsx.commit()\n",
      "    wuvt_fpsx.close()\n",
      "```\n",
      "\n",
      "### Rank 2 | Score: 0.7053757\n",
      "\n",
      "```python\n",
      "def qwhv_wajx(gpud_rqyi, uihc_lbkz):\n",
      "    kgsk_srjd = sqlite3.connect(gpud_rqyi)\n",
      "    yzgh_mbwd = kgsk_srjd.cursor()\n",
      "    yzgh_mbwd.execute('DELETE FROM items WHERE id = ?', (uihc_lbkz,))\n",
      "```\n",
      "\n",
      "### Rank 3 | Score: 0.6970219\n",
      "\n",
      "```python\n",
      "def xloq_gnth(gpud_rqyi):\n",
      "    ylrq_jxwp = sqlite3.connect(gpud_rqyi)\n",
      "    qick_glok = ylrq_jxwp.cursor()\n",
      "```\n",
      "\n",
      "No result contained all expected keywords. ❌\n",
      "\n",
      "## Test 5: Random BST creation\n",
      "\n",
      "**Query**: How do I build a random BST with a specified number of nodes?\n",
      "\n",
      "**Expected Keywords**: random_bst, NodeTree, insert_into_bst\n",
      "\n",
      "### Rank 1 | Score: 0.68067735\n",
      "\n",
      "```python\n",
      "hgje_gbno = random.randint(1, 28)\n",
      "    elif kxmn_pwfy in [4, 6, 9, 11]:\n",
      "        hgje_gbno = random.randint(1, 30)\n",
      "    else:\n",
      "        hgje_gbno = random.randint(1, 31)\n",
      "```\n",
      "\n",
      "### Rank 2 | Score: 0.674662\n",
      "\n",
      "```python\n",
      "return list(ybgd_zvsa)\n",
      "```\n",
      "\n",
      "### Rank 3 | Score: 0.67387223\n",
      "\n",
      "```python\n",
      "break\n",
      "            yield xyha_pfgz\n",
      "```\n",
      "\n",
      "No result contained all expected keywords. ❌\n",
      "\n",
      "## Test 6: Web scraping with HTML parsing\n",
      "\n",
      "**Query**: Where is the function that scrapes a webpage and returns the page title and links?\n",
      "\n",
      "**Expected Keywords**: simple_web_scraper, parse_html_title, parse_html_links\n",
      "\n",
      "### Rank 1 | Score: 0.6715163\n",
      "\n",
      "```python\n",
      "def ulgu_qysf(jixm_fuiz):\n",
      "    mfgp_hvoy = r'href=[\"\\'](.*?)[\"\\']'\n",
      "    return re.findall(mfgp_hvoy, jixm_fuiz)\n",
      "```\n",
      "\n",
      "### Rank 2 | Score: 0.6602915\n",
      "\n",
      "```python\n",
      "return list(ybgd_zvsa)\n",
      "```\n",
      "\n",
      "### Rank 3 | Score: 0.6593174\n",
      "\n",
      "```python\n",
      "return \"\".join(bjyx_ulvc)\n",
      "```\n",
      "\n",
      "No result contained all expected keywords. ❌\n",
      "\n",
      "## Test 7: Random string generation\n",
      "\n",
      "**Query**: I want to generate a random alphanumeric string of a given length.\n",
      "\n",
      "**Expected Keywords**: random_alphanumeric_string, random_hex_string\n",
      "\n",
      "### Rank 1 | Score: 0.70564276\n",
      "\n",
      "```python\n",
      "return rnmc_afyn\n",
      "```\n",
      "\n",
      "### Rank 2 | Score: 0.70564276\n",
      "\n",
      "```python\n",
      "return rnmc_afyn\n",
      "```\n",
      "\n",
      "### Rank 3 | Score: 0.70235425\n",
      "\n",
      "```python\n",
      "pass\n",
      "    return gfnb_kwiy\n",
      "```\n",
      "\n",
      "No result contained all expected keywords. ❌\n",
      "\n",
      "## Test 8: Basic XOR encryption\n",
      "\n",
      "**Query**: Which function implements an XOR cipher for strings with a numeric key?\n",
      "\n",
      "**Expected Keywords**: xor_cipher, encryption, string XOR\n",
      "\n",
      "### Rank 1 | Score: 0.7084311\n",
      "\n",
      "```python\n",
      "def qfup_kbdy(xfgn_ijot):\n",
      "    return hashlib.sha256(xfgn_ijot.encode('utf-8')).hexdigest()\n",
      "```\n",
      "\n",
      "### Rank 2 | Score: 0.707716\n",
      "\n",
      "```python\n",
      "def xzvd_kcbu(lyfo_ezgt):\n",
      "    return hex(lyfo_ezgt)[2:]\n",
      "```\n",
      "\n",
      "### Rank 3 | Score: 0.6958597\n",
      "\n",
      "```python\n",
      "def xugq_jsux(htpn_yare):\n",
      "    return int(htpn_yare, 2)\n",
      "\n",
      "def gsrz_kspf(bexl_juye, wqsr_fllp):\n",
      "    wqsr_fllp = wqsr_fllp % len(bexl_juye)\n",
      "    return bexl_juye[wqsr_fllp:] + bexl_juye[:wqsr_fllp]\n",
      "```\n",
      "\n",
      "No result contained all expected keywords. ❌\n",
      "\n",
      "## Test 9: K-Means clustering\n",
      "\n",
      "**Query**: I need a class for k-means clustering on 2D points. Where can I find it?\n",
      "\n",
      "**Expected Keywords**: BasicKMeans, fit, predict, centroids\n",
      "\n",
      "### Rank 1 | Score: 0.66705036\n",
      "\n",
      "```python\n",
      "class XzlfHcqjDuuo:\n",
      "    def __init__(zlkp, vtub_szuv, kjqp_nohi):\n",
      "        zlkp.kgpm_noim = kjqp_nohi\n",
      "```\n",
      "\n",
      "### Rank 2 | Score: 0.65721107\n",
      "\n",
      "```python\n",
      "return datetime(utmj_xevp, kxmn_pwfy, hgje_gbno)\n",
      "```\n",
      "\n",
      "### Rank 3 | Score: 0.6543391\n",
      "\n",
      "```python\n",
      "return list(ybgd_zvsa)\n",
      "```\n",
      "\n",
      "No result contained all expected keywords. ❌\n",
      "\n",
      "## Test 10: SHA-256 string hashing\n",
      "\n",
      "**Query**: How do I compute a SHA256 hash of a given string?\n",
      "\n",
      "**Expected Keywords**: hash_string_sha256, hashlib, SHA256\n",
      "\n",
      "### Rank 1 | Score: 0.6984509\n",
      "\n",
      "```python\n",
      "def qfup_kbdy(xfgn_ijot):\n",
      "    return hashlib.sha256(xfgn_ijot.encode('utf-8')).hexdigest()\n",
      "```\n",
      "\n",
      "### Rank 2 | Score: 0.68168265\n",
      "\n",
      "```python\n",
      "xxmk_yite.write(kuaf_ghst)\n",
      "```\n",
      "\n",
      "### Rank 3 | Score: 0.67789423\n",
      "\n",
      "```python\n",
      "break\n",
      "            yield xyha_pfgz\n",
      "```\n",
      "\n",
      "No result contained all expected keywords. ❌\n",
      "\n",
      "## Test 11: JSON string parsing\n",
      "\n",
      "**Query**: Which snippet can parse JSON strings and turn them into Python objects?\n",
      "\n",
      "**Expected Keywords**: parse_json_string, json.loads\n",
      "\n",
      "### Rank 1 | Score: 0.6852742\n",
      "\n",
      "```python\n",
      "import sys\n",
      "import os\n",
      "import math\n",
      "import random\n",
      "import sqlite3\n",
      "import urllib.request\n",
      "import urllib.parse\n",
      "import http.client\n",
      "import socket\n",
      "import itertools\n",
      "import json\n",
      "import re\n",
      "import csv\n",
      "```\n",
      "\n",
      "### Rank 2 | Score: 0.6720381\n",
      "\n",
      "```python\n",
      "def tknu_yqnd(itdh_jela):\n",
      "    with urllib.request.urlopen(itdh_jela) as kgxo_vqiy:\n",
      "        return kgxo_vqiy.read().decode('utf-8')\n",
      "\n",
      "def xmvl_fwvd(qptn_zwlu):\n",
      "    return json.loads(qptn_zwlu)\n",
      "```\n",
      "\n",
      "### Rank 3 | Score: 0.67110825\n",
      "\n",
      "```python\n",
      "def wlct_kxqy(yvok_brtz, oslm_wxvd):\n",
      "    with open(yvok_brtz, 'w', encoding='utf-8') as gkpj_eyic:\n",
      "        json.dump(oslm_wxvd, gkpj_eyic)\n",
      "```\n",
      "\n",
      "No result contained all expected keywords. ❌\n",
      "\n",
      "## Test 12: Simple socket server\n",
      "\n",
      "**Query**: I want a function that sets up a basic TCP server to echo data in uppercase.\n",
      "\n",
      "**Expected Keywords**: simple_socket_server, socket, listen, accept\n",
      "\n",
      "### Rank 1 | Score: 0.69686335\n",
      "\n",
      "```python\n",
      "dkvo_mcqz, fctr_sshw = qjwv_srfy.accept()\n",
      "    dkvo_mcqz.send(b'220 mock smtp server ready\\r\\n')\n",
      "    xfzw_ubrw = dkvo_mcqz.recv(1024)\n",
      "    dkvo_mcqz.send(b'250 OK\\r\\n')\n",
      "    dkvo_mcqz.close()\n",
      "```\n",
      "\n",
      "### Rank 2 | Score: 0.6928403\n",
      "\n",
      "```python\n",
      "def czbz_gebv(jnlf_yxlk, rpns_hvuf):\n",
      "    qjwv_srfy = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\n",
      "    qjwv_srfy.bind((jnlf_yxlk, rpns_hvuf))\n",
      "    qjwv_srfy.listen(1)\n",
      "```\n",
      "\n",
      "### Rank 3 | Score: 0.6913533\n",
      "\n",
      "```python\n",
      "sygt, hjkv = wvph_buzq.accept()\n",
      "    rpal_ysmq = sygt.recv(1024)\n",
      "    sygt.sendall(rpal_ysmq.upper())\n",
      "    sygt.close()\n",
      "    wvph_buzq.close()\n",
      "```\n",
      "\n",
      "No result contained all expected keywords. ❌\n",
      "\n",
      "## Test 13: BFS graph traversal\n",
      "\n",
      "**Query**: Show me the BFS graph code that returns nodes in breadth-first order.\n",
      "\n",
      "**Expected Keywords**: BFSGraph, bfs, deque, adj\n",
      "\n",
      "### Rank 1 | Score: 0.7080984\n",
      "\n",
      "```python\n",
      "return \"\".join(bjyx_ulvc)\n",
      "```\n",
      "\n",
      "### Rank 2 | Score: 0.697449\n",
      "\n",
      "```python\n",
      "return \"\".join(vfwg_nzmi)\n",
      "```\n",
      "\n",
      "### Rank 3 | Score: 0.692996\n",
      "\n",
      "```python\n",
      "return rnmc_afyn\n",
      "```\n",
      "\n",
      "No result contained all expected keywords. ❌\n",
      "\n",
      "## Test 14: Reading CSV files\n",
      "\n",
      "**Query**: How do I read a CSV file into a list or dictionary in Python?\n",
      "\n",
      "**Expected Keywords**: read_csv_as_list, read_csv_as_dicts, csv\n",
      "\n",
      "### Rank 1 | Score: 0.7326189\n",
      "\n",
      "```python\n",
      "with open(xwvs_lbpn, 'r', encoding='utf-8', newline='') as rwpq_mwov:\n",
      "        nhug_ysea = csv.reader(rwpq_mwov, uvks_xynp)\n",
      "        return list(nhug_ysea)\n",
      "```\n",
      "\n",
      "### Rank 2 | Score: 0.7076275\n",
      "\n",
      "```python\n",
      "import sys\n",
      "import os\n",
      "import math\n",
      "import random\n",
      "import sqlite3\n",
      "import urllib.request\n",
      "import urllib.parse\n",
      "import http.client\n",
      "import socket\n",
      "import itertools\n",
      "import json\n",
      "import re\n",
      "import csv\n",
      "```\n",
      "\n",
      "### Rank 3 | Score: 0.7056657\n",
      "\n",
      "```python\n",
      "return list(ybgd_zvsa)\n",
      "```\n",
      "\n",
      "No result contained all expected keywords. ❌\n",
      "\n",
      "## Test 15: String compression with run-length encoding\n",
      "\n",
      "**Query**: Which function is responsible for compressing a string into run-length encoding?\n",
      "\n",
      "**Expected Keywords**: encode_run_length, compress_string, pairs\n",
      "\n",
      "### Rank 1 | Score: 0.68174887\n",
      "\n",
      "```python\n",
      "def hguz_lswg(hbxr_cfdu):\n",
      "    if len(hbxr_cfdu) > 1:\n",
      "        rfaa_jkwe = len(hbxr_cfdu) // 2\n",
      "        pfnl_ruxz = hbxr_cfdu[:rfaa_jkwe]\n",
      "        qmop_ytol = hbxr_cfdu[rfaa_jkwe:]\n",
      "```\n",
      "\n",
      "### Rank 2 | Score: 0.67261636\n",
      "\n",
      "```python\n",
      "def qfup_kbdy(xfgn_ijot):\n",
      "    return hashlib.sha256(xfgn_ijot.encode('utf-8')).hexdigest()\n",
      "```\n",
      "\n",
      "### Rank 3 | Score: 0.6721415\n",
      "\n",
      "```python\n",
      "zlkp.vhzu.connect((fuli_koaz, zqnp_nbik))\n",
      "    def kdwu(zlkp, gmdf_xdyi):\n",
      "        if zlkp.vhzu:\n",
      "            zlkp.vhzu.sendall(gmdf_xdyi.encode('utf-8'))\n",
      "    def mvnb(zlkp):\n",
      "```\n",
      "\n",
      "No result contained all expected keywords. ❌\n",
      "\n",
      "## Test 16: BST value search\n",
      "\n",
      "**Query**: Which snippet demonstrates searching for an item in a binary search tree?\n",
      "\n",
      "**Expected Keywords**: find_in_bst, NodeTree, BinarySearchTree\n",
      "\n",
      "### Rank 1 | Score: 0.6792794\n",
      "\n",
      "```python\n",
      "return list(ybgd_zvsa)\n",
      "```\n",
      "\n",
      "### Rank 2 | Score: 0.65246826\n",
      "\n",
      "```python\n",
      "return set(qbzo_lpae)\n",
      "```\n",
      "\n",
      "### Rank 3 | Score: 0.6514772\n",
      "\n",
      "```python\n",
      "return sykg_bvio\n",
      "```\n",
      "\n",
      "No result contained all expected keywords. ❌\n",
      "\n",
      "## Test 17: Partial censor for words\n",
      "\n",
      "**Query**: Where is the code that censors a word in a string with asterisks?\n",
      "\n",
      "**Expected Keywords**: partial_censor_string, regex, asterisks\n",
      "\n",
      "### Rank 1 | Score: 0.67399246\n",
      "\n",
      "```python\n",
      "qjwv_srfy.close()\n",
      "```\n",
      "\n",
      "### Rank 2 | Score: 0.67255664\n",
      "\n",
      "```python\n",
      "break\n",
      "            yield xyha_pfgz\n",
      "```\n",
      "\n",
      "### Rank 3 | Score: 0.6683306\n",
      "\n",
      "```python\n",
      "pass\n",
      "    return gfnb_kwiy\n",
      "```\n",
      "\n",
      "No result contained all expected keywords. ❌\n",
      "\n",
      "## Test 18: In-place list shuffling\n",
      "\n",
      "**Query**: How do I shuffle a list in place using Fisher-Yates?\n",
      "\n",
      "**Expected Keywords**: fisher_yates_shuffle, random.randint, list shuffle\n",
      "\n",
      "### Rank 1 | Score: 0.70562905\n",
      "\n",
      "```python\n",
      "return list(ybgd_zvsa)\n",
      "```\n",
      "\n",
      "### Rank 2 | Score: 0.68348897\n",
      "\n",
      "```python\n",
      "axgd_tzmp.add(rrnq_owty)\n",
      "    return list(rzbl_gmrj)\n",
      "```\n",
      "\n",
      "### Rank 3 | Score: 0.68160975\n",
      "\n",
      "```python\n",
      "return set(qbzo_lpae)\n",
      "```\n",
      "\n",
      "No result contained all expected keywords. ❌\n",
      "\n",
      "## Test 19: Naive Bayes classifier\n",
      "\n",
      "**Query**: I want a class that can log-prior and word-likelihoods for naive Bayes classification.\n",
      "\n",
      "**Expected Keywords**: BasicNaiveBayes, log_priors, word_counts, predict\n",
      "\n",
      "### Rank 1 | Score: 0.6771507\n",
      "\n",
      "```python\n",
      "class XezwLhxaSevw:\n",
      "    def __init__(zlkp, lcxz_bkfu=','):\n",
      "        zlkp.hipz = lcxz_bkfu\n",
      "    def tmay(zlkp, yzqn_vrdm):\n",
      "        oubn_zrje = yzqn_vrdm.split('\\n')\n",
      "        feeg_dqkm = []\n",
      "```\n",
      "\n",
      "### Rank 2 | Score: 0.6698772\n",
      "\n",
      "```python\n",
      "class XzlfHcqjDuuo:\n",
      "    def __init__(zlkp, vtub_szuv, kjqp_nohi):\n",
      "        zlkp.kgpm_noim = kjqp_nohi\n",
      "```\n",
      "\n",
      "### Rank 3 | Score: 0.6678869\n",
      "\n",
      "```python\n",
      "class RvokUzgnIpny:\n",
      "    def __init__(zlkp, ezqh_kovc, jgdu_ajfc):\n",
      "        zlkp.ezqh_kovc = ezqh_kovc\n",
      "        zlkp.jgdu_ajfc = jgdu_ajfc\n",
      "    def wrhp(zlkp, fxka_vbul):\n",
      "        frtb_xyie = []\n",
      "```\n",
      "\n",
      "No result contained all expected keywords. ❌\n",
      "\n",
      "## Test 20: Flatten nested lists\n",
      "\n",
      "**Query**: Which snippet shows a function for splitting and flattening nested lists?\n",
      "\n",
      "**Expected Keywords**: flatten_nested_list, isinstance, recursive list\n",
      "\n",
      "### Rank 1 | Score: 0.7270012\n",
      "\n",
      "```python\n",
      "return list(ybgd_zvsa)\n",
      "```\n",
      "\n",
      "### Rank 2 | Score: 0.699548\n",
      "\n",
      "```python\n",
      "break\n",
      "            yield xyha_pfgz\n",
      "```\n",
      "\n",
      "### Rank 3 | Score: 0.68556297\n",
      "\n",
      "```python\n",
      "ouqi_rhjz = vyrk_hbim.split()[1]\n",
      "                cwkj_rqyu.append(ouqi_rhjz)\n",
      "        return list(set(cwkj_rqyu))\n",
      "```\n",
      "\n",
      "No result contained all expected keywords. ❌\n",
      "\n",
      "## Test 21: GCD and LCM of lists\n",
      "\n",
      "**Query**: I want to compute the GCD or LCM of an entire list of numbers. Which function does that?\n",
      "\n",
      "**Expected Keywords**: gcd_of_list, lcm_of_list, sequence_gcd\n",
      "\n",
      "### Rank 1 | Score: 0.7226605\n",
      "\n",
      "```python\n",
      "return list(ybgd_zvsa)\n",
      "```\n",
      "\n",
      "### Rank 2 | Score: 0.70684916\n",
      "\n",
      "```python\n",
      "if len(srgm_lhud) > 1:\n",
      "                    ungb_srxy.add(srgm_lhud[1])\n",
      "        return list(ungb_srxy)\n",
      "```\n",
      "\n",
      "### Rank 3 | Score: 0.68427646\n",
      "\n",
      "```python\n",
      "def yqdo_jgcw(xxux_olyl):\n",
      "    return list(zip(*xxux_olyl[::-1]))\n",
      "```\n",
      "\n",
      "No result contained all expected keywords. ❌\n",
      "\n",
      "## Test 22: String rotation\n",
      "\n",
      "**Query**: How do I rotate a string to the left or right by a given number of characters?\n",
      "\n",
      "**Expected Keywords**: rotate_string_left, rotate_string_right, slicing\n",
      "\n",
      "### Rank 1 | Score: 0.67789227\n",
      "\n",
      "```python\n",
      "if len(wsnm_yhzi) + len(sotr_jwoo) + 1 <= dwix_qknm:\n",
      "            if wsnm_yhzi:\n",
      "                wsnm_yhzi += ' '\n",
      "            wsnm_yhzi += sotr_jwoo\n",
      "        else:\n",
      "```\n",
      "\n",
      "### Rank 2 | Score: 0.6684533\n",
      "\n",
      "```python\n",
      "break\n",
      "            yield xyha_pfgz\n",
      "```\n",
      "\n",
      "### Rank 3 | Score: 0.66457754\n",
      "\n",
      "```python\n",
      "if wlak_zqte.right:\n",
      "                buni_rzfz.append(wlak_zqte.right)\n",
      "        return zhun_qhon\n",
      "```\n",
      "\n",
      "No result contained all expected keywords. ❌\n",
      "\n",
      "## Test 23: Creating temp files\n",
      "\n",
      "**Query**: Which snippet shows how to create a temporary file with a random name?\n",
      "\n",
      "**Expected Keywords**: create_temp_file, os, random.randint\n",
      "\n",
      "### Rank 1 | Score: 0.6688388\n",
      "\n",
      "```python\n",
      "xxmk_yite.write(kuaf_ghst)\n",
      "```\n",
      "\n",
      "### Rank 2 | Score: 0.66555893\n",
      "\n",
      "```python\n",
      "pass\n",
      "    return gfnb_kwiy\n",
      "```\n",
      "\n",
      "### Rank 3 | Score: 0.66317064\n",
      "\n",
      "```python\n",
      "return gyum_gvdn\n",
      "```\n",
      "\n",
      "No result contained all expected keywords. ❌\n",
      "\n",
      "## Test 24: Combine dictionaries\n",
      "\n",
      "**Query**: Where is the code for merging two dictionaries by summing their values?\n",
      "\n",
      "**Expected Keywords**: combine_dictionaries, dict, summing values\n",
      "\n",
      "### Rank 1 | Score: 0.6973641\n",
      "\n",
      "```python\n",
      "return \"\".join(vfwg_nzmi)\n",
      "```\n",
      "\n",
      "### Rank 2 | Score: 0.6971749\n",
      "\n",
      "```python\n",
      "return \"\".join(bjyx_ulvc)\n",
      "```\n",
      "\n",
      "### Rank 3 | Score: 0.6959623\n",
      "\n",
      "```python\n",
      "mdyr_xevu.extend(vdbr_jjvk(ldes_qeaw, yzwu_waff, rzfz_fvhy).items())\n",
      "        else:\n",
      "            mdyr_xevu.append((yzwu_waff, ldes_qeaw))\n",
      "    return dict(mdyr_xevu)\n",
      "```\n",
      "\n",
      "No result contained all expected keywords. ❌\n",
      "\n",
      "## Test 25: Simple MultiLayer Perceptron\n",
      "\n",
      "**Query**: I want to see the code for a minimal feed-forward MLP with random weights. Where is it?\n",
      "\n",
      "**Expected Keywords**: MultiLayerPerceptronMinimal, activation, forward, hidden size\n",
      "\n",
      "### Rank 1 | Score: 0.6788452\n",
      "\n",
      "```python\n",
      "return ejko_vmuf.index(min(ejko_vmuf))\n",
      "```\n",
      "\n",
      "### Rank 2 | Score: 0.67198706\n",
      "\n",
      "```python\n",
      "class GpoiMuvkHhbl:\n",
      "    def __init__(rgqw, kjnw_bmpv, qnth_umrh, fneq_dxyz):\n",
      "        rgqw.xmho = [[random.uniform(-1,1) for _ in range(qnth_umrh)] for __ in range(kjnw_bmpv)]\n",
      "```\n",
      "\n",
      "### Rank 3 | Score: 0.6641691\n",
      "\n",
      "```python\n",
      "zlkp.kmfv = [[random.uniform(-0.1, 0.1) for _ in range(kjqp_nohi)] for __ in range(kjqp_nohi)]\n",
      "        zlkp.huqz = [0]*kjqp_nohi\n",
      "    def swgb(zlkp, eulk_fcxw, mdje_gvyi):\n",
      "```\n",
      "\n",
      "No result contained all expected keywords. ❌\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "from urllib3.exceptions import InsecureRequestWarning\n",
    "\n",
    "warnings.simplefilter(\"ignore\", InsecureRequestWarning)\n",
    "\n",
    "markdown_output = []\n",
    "\n",
    "for idx, test in enumerate(test_queries, start=1):\n",
    "    user_query = test[\"query\"]\n",
    "    results = vector_search_opensearch(user_query, k=3)\n",
    "    \n",
    "    md_section = []\n",
    "    md_section.append(f\"## Test {idx}: {test['description']}\\n\")\n",
    "    md_section.append(f\"**Query**: {user_query}\\n\")\n",
    "    md_section.append(f\"**Expected Keywords**: {', '.join(test['expected_keywords'])}\\n\")\n",
    "    \n",
    "    for rank, hit in enumerate(results, start=1):\n",
    "        score = hit[\"_score\"]\n",
    "        text_snippet = hit[\"_source\"][\"text\"]\n",
    "        \n",
    "        md_section.append(f\"### Rank {rank} | Score: {score}\\n\")\n",
    "        md_section.append(\"```python\")\n",
    "        md_section.append(text_snippet)\n",
    "        md_section.append(\"```\\n\")\n",
    "    \n",
    "    # Simple keyword check\n",
    "    expected_any = any(\n",
    "        all(kw.lower() in hit[\"_source\"][\"text\"].lower() for kw in test[\"expected_keywords\"])\n",
    "        for hit in results\n",
    "    )\n",
    "    if expected_any:\n",
    "        md_section.append(\"At least one result contains the expected keywords. ✅\\n\")\n",
    "    else:\n",
    "        md_section.append(\"No result contained all expected keywords. ❌\\n\")\n",
    "    \n",
    "    markdown_output.append(\"\\n\".join(md_section))\n",
    "\n",
    "final_markdown = \"\\n\".join(markdown_output)\n",
    "\n",
    "# Print in the cell output as Markdown\n",
    "print(final_markdown)\n",
    "\n",
    "# Save to a .md file\n",
    "with open(f\"out/search_results_{os.path.split(sample_file_path)[-1]}.md\", \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(final_markdown)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Analysis of Common Mistakes\n",
    "\n",
    "Here we review potential mismatches:\n",
    "- If the system returns text snippets that have keywords but do not represent the intended functionality, it indicates the model or search relies too heavily on keyword overlap.\n",
    "- If we see partial code or code that is thematically similar but not correct, it might point to an embedding shortcoming.\n",
    "\n",
    "# Potential Solutions:\n",
    "1. Metadata Filtering: \n",
    "   We can store additional metadata (function names, docstrings, or file segment categories) in the index. Then filter or boost relevant fields.\n",
    "2. Re-ranking:\n",
    "   After retrieving top k=10 or so, we can apply a second step re-rank using more precise similarity scoring or cross-encoder approaches.\n",
    "3. Chunking/Context Adjustments:\n",
    "   Larger chunk overlap or different chunk sizes could yield more cohesive snippet retrieval.\n",
    "\n",
    "# Final Accuracy Metrics:\n",
    "You can design a custom evaluation by manually labeling correct/incorrect matches for each query. \n",
    "The final step is to compute metrics (e.g., recall@k, precision@k) for an objective view of search performance.\n",
    "\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MachineLearning",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
